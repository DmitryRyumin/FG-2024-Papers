<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&height=115&color=2C2A2E&text=FG-2024-Papers&section=header&reversal=false&textBg=false&fontAlign=50&fontSize=36&fontColor=FFFFFF&animation=scaleIn&fontAlignY=18" alt="FG-2024-Papers">
</p>

<table align="center">
  <tr>
    <td><strong>General Information</strong></td>
    <td>
      <a href="https://github.com/sindresorhus/awesome">
        <img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" alt="Awesome">
      </a>
      <a href="https://fg2024.ieee-biometrics.org/">
        <img src="http://img.shields.io/badge/FG-2024-001B37.svg" alt="Conference">
      </a>
      <img src="https://img.shields.io/badge/version-v0.0.0-rc0" alt="Version">
      <a href ="https://github.com/DmitryRyumin/FG-2024-Papers/blob/main/LICENSE">
        <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License: MIT">
      </a>
    </td>
  </tr>
  <tr>
    <td><strong>Repository Size and Activity</strong></td>
    <td>
      <img src="https://img.shields.io/github/repo-size/DmitryRyumin/FG-2024-Papers" alt="GitHub repo size">
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/commits/main/">
        <img src="https://img.shields.io/github/commit-activity/t/dmitryryumin/FG-2024-Papers" alt="GitHub commit activity (branch)">
      </a>
    </td>
  </tr>
  <tr>
    <td><strong>Contribution Statistics</strong></td>
    <td>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/graphs/contributors">
        <img src="https://img.shields.io/github/contributors/dmitryryumin/FG-2024-Papers" alt="GitHub contributors">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/issues?q=is%3Aissue+is%3Aclosed">
        <img src="https://img.shields.io/github/issues-closed/DmitryRyumin/FG-2024-Papers" alt="GitHub closed issues">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/issues">
        <img src="https://img.shields.io/github/issues/DmitryRyumin/FG-2024-Papers" alt="GitHub issues">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/pulls?q=is%3Apr+is%3Aclosed">
        <img src="https://img.shields.io/github/issues-pr-closed/DmitryRyumin/FG-2024-Papers" alt="GitHub closed pull requests">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/pulls">
        <img src="https://img.shields.io/github/issues-pr/dmitryryumin/FG-2024-Papers" alt="GitHub pull requests">
      </a>
    </td>
  </tr>
  <tr>
    <td><strong>Other Metrics</strong></td>
    <td>
      <img src="https://img.shields.io/github/last-commit/DmitryRyumin/FG-2024-Papers" alt="GitHub last commit">
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/watchers">
        <img src="https://img.shields.io/github/watchers/dmitryryumin/FG-2024-Papers?style=flat" alt="GitHub watchers">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/forks">
        <img src="https://img.shields.io/github/forks/dmitryryumin/FG-2024-Papers?style=flat" alt="GitHub forks">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/stargazers">
        <img src="https://img.shields.io/github/stars/dmitryryumin/FG-2024-Papers?style=flat" alt="GitHub Repo stars">
      </a>
      <img src="https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2FDmitryRyumin%2FFG-2024-Papers&label=Visitors&countColor=%23263759&style=flat" alt="Visitors">
    </td>
  </tr>
  <tr>
    <td><strong>Application</strong></td>
    <td>
      <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
        <img src="https://img.shields.io/badge/ü§ó-NewEraAI--Papers-FFD21F.svg" alt="App" />
      </a>
    </td>
  </tr>
  <tr>
    <td colspan="2" align="center"><strong>Progress Status</strong></td>
  </tr>
  <tr>
    <td><strong>Main</strong></td>
    <td>
      <!-- 121/2/121 -->
      <div style="float:left;">
        <img src="https://geps.dev/progress/50?successColor=006600" alt="" />
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/completed_checkmark_done.svg" width="25" alt="" />
      </div>
    </td>
  </tr>
</table>

---

FG 2024 Papers: Explore a comprehensive collection of innovative research papers presented at [*FG 2024*](https://fg2024.ieee-biometrics.org/), one of the premier conferences on automatic face and gesture recognition. Seamlessly integrate code implementations for better understanding. ‚≠ê Experience the cutting edge of progress in facial analysis, gesture recognition, and biometrics with this repository!

<p align="center">
    <a href="https://fg2024.ieee-biometrics.org/" target="_blank">
        <img width="600" src="https://github.com/DmitryRyumin/FG-2024-Papers/blob/main/images/FG2024-banner.png" alt="FG 2024">
    </a>
<p>

---

> [!TIP]
> [*The online version of the FG 2024 Conference Program*](https://fg2024.ieee-biometrics.org/conference-program/), includes a comprehensive table listing all accepted papers, along with the detailed schedule for Pre- and Post-Workshops, Oral Sessions, Demos, and Poster sessions.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" alt="" />
  Other collections of the best AI conferences
</a>

<br />
<br />

<a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://img.shields.io/badge/ü§ó-NewEraAI--Papers-FFD21F.svg" alt="App" />
</a>

<br />
<br />

> [!important]
> Conference table will be up to date all the time.

<table>
    <tr>
        <td rowspan="2" align="center"><strong>Conference</strong></td>
        <td colspan="2" align="center"><strong>Year</strong></td>
    </tr>
    <tr>
        <td colspan="1" align="center"><i>2023</i></td>
        <td colspan="1" align="center"><i>2024</i></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Computer Vision (CV)</i></td>
    </tr>
    <tr>
        <td>CVPR</td>
        <td colspan="2" align="center"><a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/CVPR-2023-24-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>ICCV</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/ICCV-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/ICCV-2023-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
        <td align="center"><img src="https://img.shields.io/badge/Not%20Scheduled-CC5540" alt=""/></td>
    </tr>
    <tr>
        <td>ECCV</td>
        <td align="center"><img src="https://img.shields.io/badge/Not%20Scheduled-CC5540" alt=""/></td>
        <td align="center"><img src="https://img.shields.io/badge/October-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>WACV</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/WACV-2024-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/WACV-2024-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
    </tr>
    <tr>
        <td>FG</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/FG-2024-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/FG-2024-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Speech/Signal Processing (SP/SigProc)</i></td>
    </tr>
    <tr>
        <td>ICASSP</td>
        <td colspan="2" align="center"><a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/ICASSP-2023-24-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>INTERSPEECH</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/INTERSPEECH-2023-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
        <td align="center"><img src="https://img.shields.io/badge/September-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>ISMIR</td>
        <td align="center"><a href="https://github.com/yamathcy/ISMIR-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/yamathcy/ISMIR-2023-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
        <td align="center">:heavy_minus_sign:</td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Natural Language Processing (NLP)</i></td>
    </tr>
    <tr>
        <td>EMNLP</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/EMNLP-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/EMNLP-2023-Papers?style=flat" alt="" /></a></td>
        <td align="center"><img src="https://img.shields.io/badge/December-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Machine Learning (ML)</i></td>
    </tr>
    <tr>
        <td>AAAI</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/AAAI-2024-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/AAAI-2024-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>ICLR</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><img src="https://img.shields.io/badge/May-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>ICML</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><img src="https://img.shields.io/badge/July-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>NeurIPS</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><img src="https://img.shields.io/badge/December-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
</table>

---

## Contributors

<a href="https://github.com/DmitryRyumin/FG-2024-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=DmitryRyumin/FG-2024-Papers" alt="" />
</a>

<br />
<br />

> [!NOTE]
> Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/FG-2024-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/FG-2024-Papers/issues) or contact me via [*email*](mailto:neweraairesearch@gmail.com)**. Your participation is crucial to making this repository even better.

---

## <a href="https://fg2024.ieee-biometrics.org/" target="_blank">Papers <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/ai.svg" width="30" alt="" /></a>

<a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://img.shields.io/badge/ü§ó-NewEraAI--Papers-FFD21F.svg" alt="App" />
</a>

> [!important]
> Final paper links will be added as soon as the [*proceedings*](https://www.computer.org/csdl/proceedings/1000065) are available.

<details open>
<summary>List of sections<a id="sections"></a></summary>

- [Best Reviewed Papers](#best-reviewed-papers)
- [Best Reviewed Student Papers](#best-reviewed-student-papers)
- [Face Biometrics](#face-biometrics)
- [Facial Expressions](#facial-expressions)
- [Human Pose and Motion](#human-pose-and-motion)
- [Gait and Action](#gait-and-action)
- [Hand and Sign Language](#hand-and-sign-language)
- [Animation, Synthesis and Self-Supervision](#animation-synthesis-and-self-supervision)
- [Posters](#posters)
- [Demo presentation](#demo-presentation)

</details>

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Best Reviewed Papers

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-0-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| An Active-Gaze Morphable Model for 3D Gaze Estimation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Occluded Person Retrieval with Hierarchical Feature Optimization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| High-Resolution Image Enumeration for Low-Resolution Face Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| OpenThermalPose: An Open-Source Annotated Thermal Human Pose Dataset and Initial YOLOv8-Pose Baselines | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Best Reviewed Student Papers

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-1-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| A Unified Model for Gaze Following and Social Gaze Prediction | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| DrFER: Learning Disentangled Representations for 3D Facial Expression Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.08318-b31b1b.svg)](https://arxiv.org/abs/2403.08318) | :heavy_minus_sign: |
| ClipSwap: Towards High Fidelity Face Swapping via Attribute and CLIP-Informed Loss | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Multi-Modal Human Behaviour Graph Representation Learning for Automatic Depression Assessment | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Face Biometrics

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-2-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Designing Cross-Race Tests for Forensic Facial Examiners, Super-Recognizers, and Face Recognition Algorithm | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TetraLoss: Improving the Robustness of Face Recognition against Morphing Attacks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2401.11598-b31b1b.svg)](https://arxiv.org/abs/2401.11598) | :heavy_minus_sign: |
| Hierarchical Generative Network for Face Morphing Attacks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.11101-b31b1b.svg)](https://arxiv.org/abs/2403.11101) | :heavy_minus_sign: |
| Face Anti-Spoofing via Interaction Learning with Face Image Quality Alignment | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Facial Expressions

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-4-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial Expression Spotting | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.15994-b31b1b.svg)](https://arxiv.org/abs/2403.15994) | :heavy_minus_sign: |
| epsilon-Mesh Attack: A Surface-based Adversarial Point Cloud Attack for Facial Expression Recognition | [![GitHub](https://img.shields.io/github/stars/batuceng/e-mesh-attack?style=flat)](https://github.com/batuceng/e-mesh-attack) | [![arXiv](https://img.shields.io/badge/arXiv-2403.06661-b31b1b.svg)](https://arxiv.org/abs/2403.06661) | :heavy_minus_sign: |
| Distilling Privileged Multimodal Information for Expression Recognition using Optimal Transport | [![GitHub](https://img.shields.io/github/stars/haseebaslam95/PKDOT?style=flat)](https://github.com/haseebaslam95/PKDOT) | [![arXiv](https://img.shields.io/badge/arXiv-2401.15489-b31b1b.svg)](https://arxiv.org/abs/2401.15489) | :heavy_minus_sign: |
| CSTalk: Correlation Supervised Speech-Driven 3D Emotional Facial Animation Generation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.18604-b31b1b.svg)](https://arxiv.org/abs/2404.18604) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Human Pose and Motion

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-2-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-1-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Uncalibrated Multi-View 3D Human Pose Estimation with Geometry Driven Attention | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Geometry-Biased Transformer for Robust Multi-View 3D Human Pose Reconstruction | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2312.17106-b31b1b.svg)](https://arxiv.org/abs/2312.17106) | :heavy_minus_sign: |
| BEAVP: A Bidirectional Enhanced Adversarial Model for Video Prediction | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CasCalib: Cascaded Calibration for Motion Capture from Sparse Unsynchronized Cameras | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://open.library.ubc.ca/soa/cIRcle/collections/ubctheses/24/items/1.0437869) <br /> [![GitHub](https://img.shields.io/github/stars/jamestang1998/CasCalib?style=flat)](https://github.com/jamestang1998/CasCalib) | [![arXiv](https://img.shields.io/badge/arXiv-2405.06845-b31b1b.svg)](https://arxiv.org/abs/2405.06845) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Gait and Action

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-2-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Unveiling Gender Effects in Gait Recognition using Conditional-Matched Bootstrap Analysis | [![GitHub](https://img.shields.io/github/stars/azimIbragimov/gait-gender?style=flat)](https://github.com/azimIbragimov/gait-gender) | :heavy_minus_sign: | :heavy_minus_sign: |
| GaitPT: Skeletons are All You Need for Gait Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.10623-b31b1b.svg)](https://arxiv.org/abs/2308.10623) | :heavy_minus_sign: |
| Attention Prompt Tuning: Parameter-Efficient Adaptation of Pre-trained Models for Action Recognition | [![GitHub](https://img.shields.io/github/stars/wgcban/apt?style=flat)](https://github.com/wgcban/apt) | [![arXiv](https://img.shields.io/badge/arXiv-2403.06978-b31b1b.svg)](https://arxiv.org/abs/2403.06978) | :heavy_minus_sign: |
| ViewDiffGait: View Pyramid Diffusion for Gait Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Hand and Sign Language

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-2-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-1-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Two Hands are Better than One: Resolving Hand to Hand Intersections via Occupancy Networks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.05414-b31b1b.svg)](https://arxiv.org/abs/2404.05414) | :heavy_minus_sign: |
| SynthSL: Expressive Humans for Sign Language Image Synthesis | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| A Gloss-Free Sign Language Production with Discrete Representation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| In My Perspective, in My Hands: Accurate Egocentric 2D Hand Pose and Action Recognition | [![GitHub](https://img.shields.io/github/stars/wiktormucha/effhandegonet?style=flat)](https://github.com/wiktormucha/effhandegonet) | [![arXiv](https://img.shields.io/badge/arXiv-2404.09308-b31b1b.svg)](https://arxiv.org/abs/2404.09308) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Animation, Synthesis and Self-Supervision

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-2-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| EAT-Face: Emotion-Controllable Audio-Driven Talking Face Generation via Diffusion Model | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Embedded Representation Learning Network for Animating Styled Video Portrait | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.19038-b31b1b.svg)](https://arxiv.org/abs/2404.19038) | :heavy_minus_sign: |
| Giving a Hand to Diffusion Models: A Two-Stage Approach to Improving Conditional Human Image Generation | [![GitHub](https://img.shields.io/github/stars/apelykh/hand-to-diffusion?style=flat)](https://github.com/apelykh/hand-to-diffusion) | [![arXiv](https://img.shields.io/badge/arXiv-2403.10731-b31b1b.svg)](https://arxiv.org/abs/2403.10731) | :heavy_minus_sign: |
| RS-rPPG: Robust Self-Supervised Learning for rPPG | [![GitHub](https://img.shields.io/github/stars/marukosan93/RS-rPPG?style=flat)](https://github.com/marukosan93/RS-rPPG) | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Posters

![Section Papers](https://img.shields.io/badge/Section%20Papers-87-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-18-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-12-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Efficient Verification-based Face Identification | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2312.13240-b31b1b.svg)](https://arxiv.org/abs/2312.13240) | :heavy_minus_sign: |
| Dataset Infant Anonymization with Pose and Emotion Retention | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Face the Needle: Predicting Risk of Fear and Fainting During Blood Donation through Video Analysis | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Intra-Person Camera Adversarial for Intra-Camera Supervised Person Re-Identification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Adaptive Cross-Architecture Mutual Knowledge Distillation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ASPECD: Adaptable Soft-Biometric Privacy-Enhancement using Centroid Decoding for Face Verification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Young Labeled Faces in the Wild (YLFW): A Dataset for Children Faces Recognition | [![GitHub](https://img.shields.io/github/stars/visteam-isr-uc/YLFW?style=flat)](https://github.com/visteam-isr-uc/YLFW) | [![arXiv](https://img.shields.io/badge/arXiv-2301.05776-b31b1b.svg)](https://arxiv.org/abs/2301.05776) | :heavy_minus_sign: |
| Deepfake: Classifiers, Fairness, and Demographically Robust Algorithm | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| PointFaceFormer: Local and Global Attention based Transformer for 3D Point Cloud Face Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Subject-based Domain Adaptation for Facial Expression Recognition | [![GitHub](https://img.shields.io/github/stars/osamazeeshan/Subject-Based-Domain-Adaptation-for-FER?style=flat)](https://github.com/osamazeeshan/Subject-Based-Domain-Adaptation-for-FER) | [![arXiv](https://img.shields.io/badge/arXiv-2312.05632-b31b1b.svg)](https://arxiv.org/abs/2312.05632) | :heavy_minus_sign: |
| Efficient Detection of Disguised Faces using Photos/Sketches from Low-Quality Surveillance Footage | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Lip and Speech Synchronization using Supervised Contrastive Learning and Cross-Modal Attention | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| If it's not Enough, Make it so: Reducing Authentic Data Demand in Face Recognition through Synthetic Faces | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.03537-b31b1b.svg)](https://arxiv.org/abs/2404.03537) | :heavy_minus_sign: |
| Data Augmentation Techniques for Enhanced Facial Landmarks Detection in Patients with Repaired Cleft Lip and Palate | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Deep Adaptative Spectral Zoom for Improved Remote Heart Rate Estimation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.06902-b31b1b.svg)](https://arxiv.org/abs/2403.06902) | :heavy_minus_sign: |
| Bridging the Gap: Protocol Towards Fair and Consistent Affect Analysis | [![GitHub](https://img.shields.io/github/stars/dkollias/Fair-Consistent-Affect-Analysis?style=flat)](https://github.com/dkollias/Fair-Consistent-Affect-Analysis) | [![arXiv](https://img.shields.io/badge/arXiv-2405.06841-b31b1b.svg)](https://arxiv.org/abs/2405.06841) | :heavy_minus_sign: |
| ONOT: a High-Quality ICAO-Compliant Synthetic Mugshot Dataset | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://miatbiolab.csr.unibo.it/icao-synthetic-dataset/) | [![arXiv](https://img.shields.io/badge/arXiv-2404.11236-b31b1b.svg)](https://arxiv.org/abs/2404.11236) | :heavy_minus_sign: |
| RFIS-FPI: Reversible Face Image Steganography Neural Network for Face Privacy Interactions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Unlocking the Black Box: Concept-based Modeling for Interpretable Affective Computing Applications | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Social-MAE: A Transformer-based Multimodal Autoencoder for Face and Voice | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Guided Interpretable Facial Expression Recognition via Spatial Action Unit Cues | [![GitHub](https://img.shields.io/github/stars/sbelharbi/interpretable-fer-aus?style=flat)](https://github.com/sbelharbi/interpretable-fer-aus) | [![arXiv](https://img.shields.io/badge/arXiv-2402.00281-b31b1b.svg)](https://arxiv.org/abs/2402.00281) | :heavy_minus_sign: |
| AerialFace: A Light Weight Framework for Unmanned Aerial Vehicle Face Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| QGFace: Quality-Guided Joint Training for Mixed Quality Face Recognition | [![GitHub](https://img.shields.io/github/stars/IsidoreSong/QGFace?style=flat)](https://github.com/IsidoreSong/QGFace) | [![arXiv](https://img.shields.io/badge/arXiv-2312.17494-b31b1b.svg)](https://arxiv.org/abs/2312.17494) | :heavy_minus_sign: |
| EmoCLIP: A Vision-Language Method for Zero-Shot Video Facial Expression Recognition | [![GitHub](https://img.shields.io/github/stars/NickyFot/EmoCLIP?style=flat)](https://github.com/NickyFot/EmoCLIP) | [![arXiv](https://img.shields.io/badge/arXiv-2310.16640-b31b1b.svg)](https://arxiv.org/abs/2310.16640) | :heavy_minus_sign: |
| In-Domain Inversion for Improved 3D Face Alignment on Asymmetrical Expressions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| 3D Face Modeling via Weakly-Supervised Disentanglement Network Joint Identity-Consistency Prior | [![GitHub](https://img.shields.io/github/stars/liguohao96/WSDF?style=flat)](https://github.com/liguohao96/WSDF) | [![arXiv](https://img.shields.io/badge/arXiv-2404.16536-b31b1b.svg)](https://arxiv.org/abs/2404.16536) | :heavy_minus_sign: |
| Expression-Aware Masking and Progressive Decoupling for Cross-Database Facial Expression Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Explainable Face Verification via Feature-Guided Gradient Backpropagation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.04549-b31b1b.svg)](https://arxiv.org/abs/2403.04549) | :heavy_minus_sign: |
| One-Stage Open-Vocabulary Temporal Action Detection Leveraging Temporal Multi-Scale and Action Label Features | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.19542-b31b1b.svg)](https://arxiv.org/abs/2404.19542) | :heavy_minus_sign: |
| Skeleton-based Self-Supervised Feature Extraction for Improved Dynamic Hand Gesture Recognition | [![GitHub](https://img.shields.io/github/stars/o-ikne/SkelMAE?style=flat)](https://github.com/o-ikne/SkelMAE) | :heavy_minus_sign: | :heavy_minus_sign: |
| Human Action Recognition with Multi-Level Granularity and Pair-Wise Hyper GCN | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MGRFormer: A Multimodal Transformer Approach for Surgical Gesture Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CCDb-HG: Novel Annotations and Gaze-Aware Representations for Head Gesture Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| GestSpoof: Gesture based Spatio-Temporal Representation Learning for Robust Fingerprint Presentation Attack Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Spatio Temporal Sparse Graph Convolution Network for Hand Gesture Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Crowd Detection via Point Localization with Diffusion Models | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| MIMIC-Pose: Implicit Membership Discrimination of Body Joints for Human Pose Estimation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| DPA-2D: Depth Propagation and Alignment with 2D Observations Guidance for Human Mesh Recovery | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Evaluating Recent 2D Human Pose Estimators for 2D-3D Pose Lifting | [![GitHub](https://img.shields.io/github/stars/TaatiTeam/2DEstimatorEval?style=flat)](https://github.com/TaatiTeam/2DEstimatorEval) | :heavy_minus_sign: | :heavy_minus_sign: |
| The Paradox of Motion: Evidence for Spurious Correlations in Skeleton-based Gait Recognition Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2402.08320-b31b1b.svg)](https://arxiv.org/abs/2402.08320) | :heavy_minus_sign: |
| Improving 2D Human Pose Estimation in Unseen Camera Views with Synthetic Data | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| DualH: A Dual Hierarchical Model for Temporal Action Localization | [![GitHub](https://img.shields.io/github/stars/zz202/DualH?style=flat)](https://github.com/zz202/DualH) | :heavy_minus_sign: | :heavy_minus_sign: |
| HR-xNet: A Novel High-Resolution Network for Human Pose Estimation with Low Resource Consumption | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Cross-Block Fine-Grained Semantic Cascade for Skeleton-based Sports Action Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.19383-b31b1b.svg)](https://arxiv.org/abs/2404.19383) | :heavy_minus_sign: |
| HM-Auth: Redefining User Authentication in Immersive Virtual World through Hand Movement Signatures | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| A Data-Driven Representation for Sign Language Production | [![GitHub](https://img.shields.io/github/stars/walsharry/VQ_SLP_Demos?style=flat)](https://github.com/walsharry/VQ_SLP_Demos) | [![arXiv](https://img.shields.io/badge/arXiv-2404.11499-b31b1b.svg)](https://arxiv.org/abs/2404.11499) | :heavy_minus_sign: |
| Diversity-Aware Sign Language Production through a Pose Encoding Variational Autoencoder | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Resource-Efficient Gesture Recognition using Low-Resolution Thermal Camera via Spiking Neural Networks and Sparse Segmentation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2401.06563-b31b1b.svg)](https://arxiv.org/abs/2401.06563) | :heavy_minus_sign: |
| Transfer Learning for Cross-Dataset Isolated Sign Language Recognition in Under-Resourced Datasets | [![GitHub](https://img.shields.io/github/stars/alpk/tid-supervised-transfer-learning-dataset?style=flat)](https://github.com/alpk/tid-supervised-transfer-learning-dataset) | [![arXiv](https://img.shields.io/badge/arXiv-2403.14534-b31b1b.svg)](https://arxiv.org/abs/2403.14534) | :heavy_minus_sign: |
| Patch-based Privacy Attention for Weakly-Supervised Privacy-Preserving Action Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Boosting Gesture Recognition with an Automatic Gesture Annotation Framework | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Towards Better Communication: Refining Hand Pose Estimation in Low-Resolution Sign Language Videos | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Quantifying Biometric Characteristics of Hand Gestures through Feature Space Probing and Identity-Level Cross-Gesture Disentanglement | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Hand Graph Topology Selection for Skeleton-based Sign Language Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Unconstrained Hand Recognition using Thermal Infrared Sensing of Dorsal Veins | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Integrating a Hierarchical Structure of Situated Human Motion in Multi-Task Learning for Professional Gesture Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Towards High Fidelity and Accurate Face Swapping | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Face-based Strategies for Evaluating Asymmetry and Speech Articulation in Patients with Craniofacial Anomalies | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Audio-Visual Person Verification based on Recursive Fusion of Joint Cross-Attention | [![GitHub](https://img.shields.io/github/stars/praveena2j/RJCAforSpeakerVerification?style=flat)](https://github.com/praveena2j/RJCAforSpeakerVerification) | [![arXiv](https://img.shields.io/badge/arXiv-2403.04654-b31b1b.svg)](https://arxiv.org/abs/2403.04654) | :heavy_minus_sign: |
| VoxAtnNet: A 3D Point Clouds Convolutional Neural Network for Generalizable Face Presentation Attack Detection | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.12680-b31b1b.svg)](https://arxiv.org/abs/2404.12680) | :heavy_minus_sign: |
| Multi-View Consistent 3D GAN Inversion via Bidirectional Encoder | [![GitHub](https://img.shields.io/github/stars/WHZMM/BiDiE?style=flat)](https://github.com/WHZMM/BiDiE) | :heavy_minus_sign: | :heavy_minus_sign: |
| Context-based Dataset for Analysis of Videos of Autistic Children | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Seeing and Hearing what has not been Said; A Multimodal Client Behavior Classifier in Motivational Interviewing with Interpretable Fusion | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2309.14398-b31b1b.svg)](https://arxiv.org/abs/2309.14398) | :heavy_minus_sign: |
| SignAvatar: Sign Language 3D Motion Reconstruction and Generation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dongludeeplearning.github.io/SignAvatar.html) | [![arXiv](https://img.shields.io/badge/arXiv-2405.07974-b31b1b.svg)](https://arxiv.org/abs/2405.07974) | :heavy_minus_sign: |
| PortraitDAE: Line-Drawing Portraits Style Transfer from Photos via Diffusion Autoencoder with Meaningful Encoded Noise | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| FE-Adapter: Adapting Image-based Emotion Classifiers to Videos | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Latent Embedding Clustering for Occlusion Robust Head Pose Estimation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.20251-b31b1b.svg)](https://arxiv.org/abs/2403.20251) | :heavy_minus_sign: |
| Pivotal Tuning Editing: Towards Disentangled Wrinkle Editing with GANs | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Data-Driven but Privacy-Conscious: Pedestrian Dataset De-Identification via Full-Body Person Synthesis | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.11710-b31b1b.svg)](https://arxiv.org/abs/2306.11710) | :heavy_minus_sign: |
| CrossGaze: A Strong Method for 3D Gaze Estimation in the Wild | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2402.08316-b31b1b.svg)](https://arxiv.org/abs/2402.08316) | :heavy_minus_sign: |
| Survey of Automated Methods for Nonverbal Behavior Analysis in Parent-Child Interactions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Naive Data Augmentation Might be Toxic: Data-Prior Guided Self-Supervised Representation Learning for Micro-Gesture Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| SMCTL: Subcarrier Masking Contrastive Transfer Learning for Human Gesture Recognition with Passive Wi-Fi Sensing | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Semantic-Aware Detail Enhancement for Blind Face Restoration | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Discovering Interpretable Directions in the Semantic Latent Space of Diffusion Models | [![GitHub](https://img.shields.io/github/stars/JonasLoos/h-space-directions?style=flat)](https://github.com/JonasLoos/h-space-directions) | [![arXiv](https://img.shields.io/badge/arXiv-2303.11073-b31b1b.svg)](https://arxiv.org/abs/2303.11073) | :heavy_minus_sign: |
| Breaking Template Protection: Reconstruction of Face Images from Protected Facial Templates | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Benchmarking Skeleton-based Motion Encoder Models for Clinical Applications: Estimating Parkinson's Disease Severity in Walking Sequences | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| The Seven Faces of Stress: Understanding Facial Activity Patterns during Cognitive Stress | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Visual Coherence Face Anonymization Algorithm based on Dynamic Identity Perception | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| PyraMoT: A Novel Framework for Enhanced Facial Thermal Landmarks Detection | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Visual Saliency Guided Gaze Target Estimation with Limited Labels | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Hyp-OC: Hyperbolic One Class Classifier for Face Anti-Spoofing | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Dynamic Cross Attention for Audio-Visual Person Verification | [![GitHub](https://img.shields.io/github/stars/praveena2j/DCAforPersonVerification?style=flat)](https://github.com/praveena2j/DCAforPersonVerification) | [![arXiv](https://img.shields.io/badge/arXiv-2403.04661-b31b1b.svg)](https://arxiv.org/abs/2403.04661) | :heavy_minus_sign: |
| Enhancing Privacy in Face Analytics using Fully Homomorphic Encryption | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.16255-b31b1b.svg)](https://arxiv.org/abs/2404.16255) | :heavy_minus_sign: |
| CribNet: Enhancing Infant Safety in Cribs through Vision-based Hazard Detection | [![GitHub](https://img.shields.io/github/stars/ostadabbas/CribNet?style=flat)](https://github.com/ostadabbas/CribNet) | :heavy_minus_sign: | :heavy_minus_sign: |
| 3D Face Morphing Attack Generation using Non-Rigid Registration | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.15765-b31b1b.svg)](https://arxiv.org/abs/2404.15765) | :heavy_minus_sign: |
| BTVSL: A Novel Sentence-Level Annotated Dataset for Bangla Sign Language Translation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Demo presentation

![Section Papers](https://img.shields.io/badge/Section%20Papers-2-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-0-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Russian Sign Language Learning Simulator | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Expanding PyAFAR: A Novel Privacy-Preserving Infant AU Detector | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

---

## Key Terms

> Will soon be added

---

## Star History

<p align="center">
    <a href="https://star-history.com/#Dmitryryumin/FG-2024-Papers&Date" target="_blank">
        <img width="500" src="https://api.star-history.com/svg?repos=Dmitryryumin/FG-2024-Papers&type=Date" alt="Star History Chart">
    </a>
<p>
