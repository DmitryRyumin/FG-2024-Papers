<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&height=115&color=2C2A2E&text=FG-2024-Papers&section=header&reversal=false&textBg=false&fontAlign=50&fontSize=36&fontColor=FFFFFF&animation=scaleIn&fontAlignY=18" alt="FG-2024-Papers">
</p>

<table align="center">
  <tr>
    <td><strong>General Information</strong></td>
    <td>
      <a href="https://github.com/sindresorhus/awesome">
        <img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" alt="Awesome">
      </a>
      <a href="https://fg2024.ieee-biometrics.org/">
        <img src="http://img.shields.io/badge/FG-2024-001B37.svg" alt="Conference">
      </a>
      <img src="https://img.shields.io/badge/version-v0.0.0-rc0" alt="Version">
      <a href ="https://github.com/DmitryRyumin/FG-2024-Papers/blob/main/LICENSE">
        <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License: MIT">
      </a>
    </td>
  </tr>
  <tr>
    <td><strong>Repository Size and Activity</strong></td>
    <td>
      <img src="https://img.shields.io/github/repo-size/DmitryRyumin/FG-2024-Papers" alt="GitHub repo size">
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/commits/main/">
        <img src="https://img.shields.io/github/commit-activity/t/dmitryryumin/FG-2024-Papers" alt="GitHub commit activity (branch)">
      </a>
    </td>
  </tr>
  <tr>
    <td><strong>Contribution Statistics</strong></td>
    <td>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/graphs/contributors">
        <img src="https://img.shields.io/github/contributors/dmitryryumin/FG-2024-Papers" alt="GitHub contributors">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/issues?q=is%3Aissue+is%3Aclosed">
        <img src="https://img.shields.io/github/issues-closed/DmitryRyumin/FG-2024-Papers" alt="GitHub closed issues">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/issues">
        <img src="https://img.shields.io/github/issues/DmitryRyumin/FG-2024-Papers" alt="GitHub issues">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/pulls?q=is%3Apr+is%3Aclosed">
        <img src="https://img.shields.io/github/issues-pr-closed/DmitryRyumin/FG-2024-Papers" alt="GitHub closed pull requests">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/pulls">
        <img src="https://img.shields.io/github/issues-pr/dmitryryumin/FG-2024-Papers" alt="GitHub pull requests">
      </a>
    </td>
  </tr>
  <tr>
    <td><strong>Other Metrics</strong></td>
    <td>
      <img src="https://img.shields.io/github/last-commit/DmitryRyumin/FG-2024-Papers" alt="GitHub last commit">
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/watchers">
        <img src="https://img.shields.io/github/watchers/dmitryryumin/FG-2024-Papers?style=flat" alt="GitHub watchers">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/forks">
        <img src="https://img.shields.io/github/forks/dmitryryumin/FG-2024-Papers?style=flat" alt="GitHub forks">
      </a>
      <a href="https://github.com/DmitryRyumin/FG-2024-Papers/stargazers">
        <img src="https://img.shields.io/github/stars/dmitryryumin/FG-2024-Papers?style=flat" alt="GitHub Repo stars">
      </a>
      <img src="https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2FDmitryRyumin%2FFG-2024-Papers&label=Visitors&countColor=%23263759&style=flat" alt="Visitors">
    </td>
  </tr>
  <tr>
    <td><strong>Application</strong></td>
    <td>
      <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
        <img src="https://img.shields.io/badge/ü§ó-NewEraAI--Papers-FFD21F.svg" alt="App" />
      </a>
    </td>
  </tr>
  <tr>
    <td colspan="2" align="center"><strong>Progress Status</strong></td>
  </tr>
  <tr>
    <td><strong>Main</strong></td>
    <td>
      <!-- 57/2/118 -->
      <div style="float:left;">
        <img src="https://geps.dev/progress/24?successColor=006600" alt="" />
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/completed_checkmark_done.svg" width="25" alt="" />
      </div>
    </td>
  </tr>
</table>

---

FG 2024 Papers: Explore a comprehensive collection of innovative research papers presented at [*FG 2024*](https://fg2024.ieee-biometrics.org/), one of the premier conferences on automatic face and gesture recognition. Seamlessly integrate code implementations for better understanding. ‚≠ê Experience the cutting edge of progress in facial analysis, gesture recognition, and biometrics with this repository!

<p align="center">
    <a href="https://fg2024.ieee-biometrics.org/" target="_blank">
        <img width="600" src="https://github.com/DmitryRyumin/FG-2024-Papers/blob/main/images/FG2024-banner.png" alt="FG 2024">
    </a>
<p>

---

> [!TIP]
> [*The online version of the FG 2024 Conference Program*](https://fg2024.ieee-biometrics.org/conference-program/), includes a comprehensive table listing all accepted papers, along with the detailed schedule for Pre- and Post-Workshops, Oral Sessions, Demos, and Poster sessions.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" alt="" />
  Other collections of the best AI conferences
</a>

<br />
<br />

<a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://img.shields.io/badge/ü§ó-NewEraAI--Papers-FFD21F.svg" alt="App" />
</a>

<br />
<br />

> [!important]
> Conference table will be up to date all the time.

<table>
    <tr>
        <td rowspan="2" align="center"><strong>Conference</strong></td>
        <td colspan="2" align="center"><strong>Year</strong></td>
    </tr>
    <tr>
        <td colspan="1" align="center"><i>2023</i></td>
        <td colspan="1" align="center"><i>2024</i></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Computer Vision (CV)</i></td>
    </tr>
    <tr>
        <td>CVPR</td>
        <td colspan="2" align="center"><a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/CVPR-2023-24-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>ICCV</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/ICCV-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/ICCV-2023-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
        <td align="center"><img src="https://img.shields.io/badge/Not%20Scheduled-CC5540" alt=""/></td>
    </tr>
    <tr>
        <td>ECCV</td>
        <td align="center"><img src="https://img.shields.io/badge/Not%20Scheduled-CC5540" alt=""/></td>
        <td align="center"><img src="https://img.shields.io/badge/October-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>WACV</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/WACV-2024-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/WACV-2024-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
    </tr>
    <tr>
        <td>FG</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/FG-2024-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/FG-2024-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Speech/Signal Processing (SP/SigProc)</i></td>
    </tr>
    <tr>
        <td>ICASSP</td>
        <td colspan="2" align="center"><a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/ICASSP-2023-24-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>INTERSPEECH</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/INTERSPEECH-2023-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
        <td align="center"><img src="https://img.shields.io/badge/September-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>ISMIR</td>
        <td align="center"><a href="https://github.com/yamathcy/ISMIR-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/yamathcy/ISMIR-2023-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
        <td align="center">:heavy_minus_sign:</td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Natural Language Processing (NLP)</i></td>
    </tr>
    <tr>
        <td>EMNLP</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/EMNLP-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/EMNLP-2023-Papers?style=flat" alt="" /></a></td>
        <td align="center"><img src="https://img.shields.io/badge/December-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Machine Learning (ML)</i></td>
    </tr>
    <tr>
        <td>AAAI</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/AAAI-2024-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/AAAI-2024-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>ICLR</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><img src="https://img.shields.io/badge/May-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>ICML</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><img src="https://img.shields.io/badge/July-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>NeurIPS</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><img src="https://img.shields.io/badge/December-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
</table>

---

## Contributors

<a href="https://github.com/DmitryRyumin/FG-2024-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=DmitryRyumin/FG-2024-Papers" alt="" />
</a>

<br />
<br />

> [!NOTE]
> Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/FG-2024-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/FG-2024-Papers/issues) or contact me via [*email*](mailto:neweraairesearch@gmail.com)**. Your participation is crucial to making this repository even better.

---

## <a href="https://fg2024.ieee-biometrics.org/" target="_blank">Papers <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/ai.svg" width="30" alt="" /></a>

<a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://img.shields.io/badge/ü§ó-NewEraAI--Papers-FFD21F.svg" alt="App" />
</a>

> [!important]
> Final paper links will be added as soon as the [*proceedings*](https://www.computer.org/csdl/proceedings/1000065) are available.

<details open>
<summary>List of sections<a id="sections"></a></summary>

- [Best Reviewed Papers](#best-reviewed-papers)
- [Best Reviewed Student Papers](#best-reviewed-student-papers)
- [Face Biometrics](#face-biometrics)
- [Facial Expressions](#facial-expressions)
- [Human Pose and Motion](#human-pose-and-motion)
- [Gait and Action](#gait-and-action)
- [Hand and Sign Language](#hand-and-sign-language)
- [Animation, Synthesis and Self-Supervision](#animation-synthesis-and-self-supervision)
- [Posters](#posters)
- [Demo presentation](#demo-presentation)

</details>

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Best Reviewed Papers

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-0-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| An Active-Gaze Morphable Model for 3D Gaze Estimation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Occluded Person Retrieval with Hierarchical Feature Optimization | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| High-Resolution Image Enumeration for Low-Resolution Face Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| OpenThermalPose: An Open-Source Annotated Thermal Human Pose Dataset and Initial YOLOv8-Pose Baselines | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Best Reviewed Student Papers

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-1-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| A Unified Model for Gaze Following and Social Gaze Prediction | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| DrFER: Learning Disentangled Representations for 3D Facial Expression Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.08318-b31b1b.svg)](https://arxiv.org/abs/2403.08318) | :heavy_minus_sign: |
| ClipSwap: Towards High Fidelity Face Swapping via Attribute and CLIP-Informed Loss | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Multi-Modal Human Behaviour Graph Representation Learning for Automatic Depression Assessment | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Face Biometrics

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-2-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Designing Cross-Race Tests for Forensic Facial Examiners, Super-Recognizers, and Face Recognition Algorithm | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| TetraLoss: Improving the Robustness of Face Recognition against Morphing Attacks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2401.11598-b31b1b.svg)](https://arxiv.org/abs/2401.11598) | :heavy_minus_sign: |
| Hierarchical Generative Network for Face Morphing Attacks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.11101-b31b1b.svg)](https://arxiv.org/abs/2403.11101) | :heavy_minus_sign: |
| Face Anti-Spoofing via Interaction Learning with Face Image Quality Alignment | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Facial Expressions

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-4-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial Expression Spotting | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.15994-b31b1b.svg)](https://arxiv.org/abs/2403.15994) | :heavy_minus_sign: |
| epsilon-Mesh Attack: A Surface-based Adversarial Point Cloud Attack for Facial Expression Recognition | [![GitHub](https://img.shields.io/github/stars/batuceng/e-mesh-attack?style=flat)](https://github.com/batuceng/e-mesh-attack) | [![arXiv](https://img.shields.io/badge/arXiv-2403.06661-b31b1b.svg)](https://arxiv.org/abs/2403.06661) | :heavy_minus_sign: |
| Distilling Privileged Multimodal Information for Expression Recognition using Optimal Transport | [![GitHub](https://img.shields.io/github/stars/haseebaslam95/PKDOT?style=flat)](https://github.com/haseebaslam95/PKDOT) | [![arXiv](https://img.shields.io/badge/arXiv-2401.15489-b31b1b.svg)](https://arxiv.org/abs/2401.15489) | :heavy_minus_sign: |
| CSTalk: Correlation Supervised Speech-Driven 3D Emotional Facial Animation Generation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.18604-b31b1b.svg)](https://arxiv.org/abs/2404.18604) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Human Pose and Motion

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-2-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-1-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Uncalibrated Multi-View 3D Human Pose Estimation with Geometry Driven Attention | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Geometry-Biased Transformer for Robust Multi-View 3D Human Pose Reconstruction | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2312.17106-b31b1b.svg)](https://arxiv.org/abs/2312.17106) | :heavy_minus_sign: |
| BEAVP: A Bidirectional Enhanced Adversarial Model for Video Prediction | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| CasCalib: Cascaded Calibration for Motion Capture from Sparse Unsynchronized Cameras | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://open.library.ubc.ca/soa/cIRcle/collections/ubctheses/24/items/1.0437869) <br /> [![GitHub](https://img.shields.io/github/stars/jamestang1998/CasCalib?style=flat)](https://github.com/jamestang1998/CasCalib) | [![arXiv](https://img.shields.io/badge/arXiv-2405.06845-b31b1b.svg)](https://arxiv.org/abs/2405.06845) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Gait and Action

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-2-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Unveiling Gender Effects in Gait Recognition using Conditional-Matched Bootstrap Analysis | [![GitHub](https://img.shields.io/github/stars/azimIbragimov/gait-gender?style=flat)](https://github.com/azimIbragimov/gait-gender) | :heavy_minus_sign: | :heavy_minus_sign: |
| GaitPT: Skeletons are All You Need for Gait Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2308.10623-b31b1b.svg)](https://arxiv.org/abs/2308.10623) | :heavy_minus_sign: |
| Attention Prompt Tuning: Parameter-Efficient Adaptation of Pre-trained Models for Action Recognition | [![GitHub](https://img.shields.io/github/stars/wgcban/apt?style=flat)](https://github.com/wgcban/apt) | [![arXiv](https://img.shields.io/badge/arXiv-2403.06978-b31b1b.svg)](https://arxiv.org/abs/2403.06978) | :heavy_minus_sign: |
| ViewDiffGait: View Pyramid Diffusion for Gait Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Hand and Sign Language

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-2-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-1-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Two Hands are Better than One: Resolving Hand to Hand Intersections via Occupancy Networks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.05414-b31b1b.svg)](https://arxiv.org/abs/2404.05414) | :heavy_minus_sign: |
| SynthSL: Expressive Humans for Sign Language Image Synthesis | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| A Gloss-Free Sign Language Production with Discrete Representation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| In My Perspective, in My Hands: Accurate Egocentric 2D Hand Pose and Action Recognition | [![GitHub](https://img.shields.io/github/stars/wiktormucha/effhandegonet?style=flat)](https://github.com/wiktormucha/effhandegonet) | [![arXiv](https://img.shields.io/badge/arXiv-2404.09308-b31b1b.svg)](https://arxiv.org/abs/2404.09308) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Animation, Synthesis and Self-Supervision

> Will soon be added

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Posters

![Section Papers](https://img.shields.io/badge/Section%20Papers-28-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-12-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-7-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Efficient Verification-based Face Identification | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2312.13240-b31b1b.svg)](https://arxiv.org/abs/2312.13240) | :heavy_minus_sign: |
| Dataset Infant Anonymization with Pose and Emotion Retention | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Face the Needle: Predicting Risk of Fear and Fainting During Blood Donation through Video Analysis | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Intra-Person Camera Adversarial for Intra-Camera Supervised Person Re-Identification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Adaptive Cross-Architecture Mutual Knowledge Distillation | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| ASPECD: Adaptable Soft-Biometric Privacy-Enhancement using Centroid Decoding for Face Verification | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Young Labeled Faces in the Wild (YLFW): A Dataset for Children Faces Recognition | [![GitHub](https://img.shields.io/github/stars/visteam-isr-uc/YLFW?style=flat)](https://github.com/visteam-isr-uc/YLFW) | [![arXiv](https://img.shields.io/badge/arXiv-2301.05776-b31b1b.svg)](https://arxiv.org/abs/2301.05776) | :heavy_minus_sign: |
| Deepfake: Classifiers, Fairness, and Demographically Robust Algorithm | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| PointFaceFormer: Local and Global Attention based Transformer for 3D Point Cloud Face Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Subject-based Domain Adaptation for Facial Expression Recognition | [![GitHub](https://img.shields.io/github/stars/osamazeeshan/Subject-Based-Domain-Adaptation-for-FER?style=flat)](https://github.com/osamazeeshan/Subject-Based-Domain-Adaptation-for-FER) | [![arXiv](https://img.shields.io/badge/arXiv-2312.05632-b31b1b.svg)](https://arxiv.org/abs/2312.05632) | :heavy_minus_sign: |
| Efficient Detection of Disguised Faces using Photos/Sketches from Low-Quality Surveillance Footage | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Lip and Speech Synchronization using Supervised Contrastive Learning and Cross-Modal Attention | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| If it's not Enough, Make it so: Reducing Authentic Data Demand in Face Recognition through Synthetic Faces | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2404.03537-b31b1b.svg)](https://arxiv.org/abs/2404.03537) | :heavy_minus_sign: |
| Data Augmentation Techniques for Enhanced Facial Landmarks Detection in Patients with Repaired Cleft Lip and Palate | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Deep Adaptative Spectral Zoom for Improved Remote Heart Rate Estimation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.06902-b31b1b.svg)](https://arxiv.org/abs/2403.06902) | :heavy_minus_sign: |
| Bridging the Gap: Protocol Towards Fair and Consistent Affect Analysis | [![GitHub](https://img.shields.io/github/stars/dkollias/Fair-Consistent-Affect-Analysis?style=flat)](https://github.com/dkollias/Fair-Consistent-Affect-Analysis) | [![arXiv](https://img.shields.io/badge/arXiv-2405.06841-b31b1b.svg)](https://arxiv.org/abs/2405.06841) | :heavy_minus_sign: |
| ONOT: a High-Quality ICAO-Compliant Synthetic Mugshot Dataset | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://miatbiolab.csr.unibo.it/icao-synthetic-dataset/) | [![arXiv](https://img.shields.io/badge/arXiv-2404.11236-b31b1b.svg)](https://arxiv.org/abs/2404.11236) | :heavy_minus_sign: |
| RFIS-FPI: Reversible Face Image Steganography Neural Network for Face Privacy Interactions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Unlocking the Black Box: Concept-based Modeling for Interpretable Affective Computing Applications | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Social-MAE: A Transformer-based Multimodal Autoencoder for Face and Voice | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Guided Interpretable Facial Expression Recognition via Spatial Action Unit Cues | [![GitHub](https://img.shields.io/github/stars/sbelharbi/interpretable-fer-aus?style=flat)](https://github.com/sbelharbi/interpretable-fer-aus) | [![arXiv](https://img.shields.io/badge/arXiv-2402.00281-b31b1b.svg)](https://arxiv.org/abs/2402.00281) | :heavy_minus_sign: |
| AerialFace: A Light Weight Framework for Unmanned Aerial Vehicle Face Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| QGFace: Quality-Guided Joint Training for Mixed Quality Face Recognition | [![GitHub](https://img.shields.io/github/stars/IsidoreSong/QGFace?style=flat)](https://github.com/IsidoreSong/QGFace) | [![arXiv](https://img.shields.io/badge/arXiv-2312.17494-b31b1b.svg)](https://arxiv.org/abs/2312.17494) | :heavy_minus_sign: |
| EmoCLIP: A Vision-Language Method for Zero-Shot Video Facial Expression Recognition | [![GitHub](https://img.shields.io/github/stars/NickyFot/EmoCLIP?style=flat)](https://github.com/NickyFot/EmoCLIP) | [![arXiv](https://img.shields.io/badge/arXiv-2310.16640-b31b1b.svg)](https://arxiv.org/abs/2310.16640) | :heavy_minus_sign: |
| In-Domain Inversion for Improved 3D Face Alignment on Asymmetrical Expressions | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| 3D Face Modeling via Weakly-Supervised Disentanglement Network Joint Identity-Consistency Prior | [![GitHub](https://img.shields.io/github/stars/liguohao96/WSDF?style=flat)](https://github.com/liguohao96/WSDF) | [![arXiv](https://img.shields.io/badge/arXiv-2404.16536-b31b1b.svg)](https://arxiv.org/abs/2404.16536) | :heavy_minus_sign: |
| Expression-Aware Masking and Progressive Decoupling for Cross-Database Facial Expression Recognition | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |
| Explainable Face Verification via Feature-Guided Gradient Backpropagation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2403.04549-b31b1b.svg)](https://arxiv.org/abs/2403.04549) | :heavy_minus_sign: |

<a href="#sections">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/top.svg" alt="" />
</a>

### Demo presentation

![Section Papers](https://img.shields.io/badge/Section%20Papers-1-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-0-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-0-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /> | <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /> |
|-----------|:--------:|:---------:|:---------:|
| Russian Sign Language Learning Simulator | :heavy_minus_sign: | :heavy_minus_sign: | :heavy_minus_sign: |

---

## Key Terms

> Will soon be added

---

## Star History

<p align="center">
    <a href="https://star-history.com/#Dmitryryumin/FG-2024-Papers&Date" target="_blank">
        <img width="500" src="https://api.star-history.com/svg?repos=Dmitryryumin/FG-2024-Papers&type=Date" alt="Star History Chart">
    </a>
<p>
